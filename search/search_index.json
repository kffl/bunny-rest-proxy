{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Bunny REST Proxy documentation","text":"<p>Bunny REST Proxy is a HTTP message broker built on top of RabbitMQ. It allows services to easily publish messages into RabbitMQ queues over HTTP as well as to consume messages utilizing both pull (HTTP GET) and push (HTTP POST to a subscriber) delivery modes.</p>"},{"location":"#overview","title":"Overview","text":""},{"location":"#design-principles","title":"Design principles","text":"<p>Bunny REST Proxy design is based on the following four principles:</p>"},{"location":"#simplicity-and-ease-of-use","title":"Simplicity and ease of use","text":"<p>Bunny REST Proxy was built with simplicity and ease of use in mind. All of the important configuration is stored in a single YAML file. You can try it yourself by following the quickstart guide which takes about 5 minutes to complete.</p>"},{"location":"#message-delivery-guarantees","title":"Message delivery guarantees","text":"<p>At-least-once delivery semantics are supported out of the box thanks to the usage of channels with publishers confirms. By default, Bunny REST Proxy won't sent back a successful response to an HTTP publish request unless the message was durably persisted in the broker. Messages unsuccessfully pushed to subscribers over HTTP won't be lost either thanks to a configurable retry mechanism (with various backoff strategies) and dead letter policies.</p>"},{"location":"#flexible-integration-into-existing-systems","title":"Flexible integration into existing systems","text":"<p>Bunny REST Proxy doesn't force you to rewrite your existing distributed system that uses RabbitMQ. Instead, it allows for incremental adoption by only using a subset of its features, while leaving the rest of your AMQP-based architecture untouched.</p>"},{"location":"#horizontal-scalability","title":"Horizontal scalability","text":"<p>Multiple instances of Bunny REST Proxy can be running against a single RabbitMQ cluster without even knowing about one other. Having zero state shared between them eliminates the need for implementing distributed consensus protocols and allows each instance to be disposable/ephemeral. Consequently, Bunny REST Proxy can be painlessly scaled horizontally i.e. as a deployment in a Kubernetes cluster.</p>"},{"location":"#license","title":"License","text":"<p>Copyright \u00a9 2021-2022 Pawe\u0142 Kuffel, licensed under the Apache 2.0 license.</p>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#configyml-file","title":"<code>config.yml</code> file","text":"<p>Configuration of a Bunny REST Proxy instance is almost entirely stored in a single YAML file that is expected to be located in <code>/app/config.yml</code> when using the official Docker container image.</p> <p>The <code>config.yml</code> may contain four block types declaring the following entities:</p> <ul> <li>Publishers, which are used used in order to send messages to RabbitMQ queues over HTTP.</li> <li>Consumers used for pull-based retrieval of messages one-by-one from queues using HTTP GET requests.</li> <li>Subscribers that allow for pushing messages from a given queue to a specified target via HTTP POST requests.</li> <li>Identities used for ACL-based authorization of publisher and consumer HTTP endpoints.</li> </ul> <p>Below is a simple example of a <code>config.yml</code> file declaring a publisher and a  consumer working on a single RabbitMQ queue:</p> <pre><code>---\npublishers:\n- queueName: json-queue\ncontentType: json\n\nconsumers:\n- queueName: json-queue\n</code></pre>"},{"location":"configuration/#environment-variables","title":"Environment variables","text":"<p>The following configuration parameters can be specified via environment variables:</p> <ul> <li><code>BRP_CONN_STR</code> (required) - RabbitMQ connection string.</li> <li><code>BRP_LOG_LEVEL</code> - log level to be used by Bunny REST Proxy. Possible values are: <code>fatal</code>, <code>error</code>, <code>warn</code>, <code>info</code>, <code>debug</code>, <code>trace</code>, <code>child</code>. Defaults to <code>info</code>.</li> <li><code>BRP_LOG_PRETTY</code> - whether or not to print logs in pretty format. Defaults to <code>false</code> (using pino's default JSON log format).</li> <li><code>BRP_TOKEN_&lt;identityName&gt;</code> - authentication token for a given identity.</li> </ul>"},{"location":"deployment/","title":"Deployment","text":"<p>Warning</p> <p>Bunny REST Proxy is still under development and should not be considered production-ready at this point in time.</p> <p>Bunny REST Proxy is a stateless application that can be scaled horizontally i.e. as a deployment in a Kubernetes cluster and doesn't require persistent storage. Consequently, the majority of operational complexity comes from deploying and maintaining the underlying RabbitMQ cluster, not the Bunny REST Proxy instances themselves.</p>"},{"location":"deployment/#docker-compose","title":"Docker-compose","text":"<p>Below is a sample <code>docker-compose.yml</code> file describing a development setup that consists of RabbitMQ and Bunny REST Proxy containers (it assumes that config.yml file is located in the working directory from which <code>docker-compose</code> stack is created):</p> <pre><code>version: \"3.2\"\nservices:\n  rabbitmq:\n    image: rabbitmq:3-management\n    container_name: 'rabbitmq'\n    ports:\n      - 5672:5672\n      - 15672:15672\n    volumes:\n      - \"./data:/var/lib/rabbitmq/mnesia/\"\n    networks:\n      - bunny_net\n  bunny-rest-proxy:\n    image: kffl/bunny-rest-proxy\n    container_name: 'bunny-rest-proxy'\n    ports:\n      - 3672:3672\n      - 9672:9672\n    environment:\n      - BRP_LOG_PRETTY=true\n      - BRP_CONN_STR=amqp://guest:guest@rabbitmq:5672?heartbeat=30\n    volumes:\n      - ${PWD}/config.yml:/app/config.yml\n    restart: on-failure\n    networks:\n      - bunny_net\n\nnetworks:\n  bunny_net:\n    driver: bridge\n</code></pre>"},{"location":"deployment/#kubernetes","title":"Kubernetes","text":"<p>A config file can be mounted inside Bunny REST Proxy containers running in a deployment via a config map:</p> <pre><code>kubectl create configmap bunny-config --from-file=./config.yml\n</code></pre> <p>Example deployment definition:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: bunny-rest-proxy\nspec:\nselector:\nmatchLabels:\napp: bunny-rest-proxy\nreplicas: 3\ntemplate:\nmetadata:\nlabels:\napp: bunny-rest-proxy\nspec:\ncontainers:\n- name: bunny-rest-proxy\nimage: kffl/bunny-rest-proxy:0.1.0-rc3\nenv:\n- name: BRP_CONN_STR # in a real-world scenario, a secret should be used instead\nvalue: \"amqp://guest:guest@rabbitmq:5672?heartbeat=30\"\nvolumeMounts:\n- mountPath: '/app/config.yml'\nname: config-volume\nreadOnly: true\nsubPath: config.yml\nvolumes:\n- name: config-volume\nconfigMap:\nname: bunny-config\n</code></pre> <p>Example service definition:</p> <pre><code>apiVersion: v1\nkind: Service\nmetadata:\nname: bunny-service\nlabels:\napp: bunny-rest-proxy\nspec:\nports:\n- port: 3672\nprotocol: TCP\nname: rest-api\n- port: 9672\nprotocol: TCP\nname: metrics\nselector:\napp: bunny-rest-proxy\n</code></pre> <p>Example service monitor definition that instructs <code>prometheus-operator</code> to scrape metrics from Bunny REST Proxy:</p> <pre><code>apiVersion: monitoring.coreos.com/v1\nkind: ServiceMonitor\nmetadata:\nname: bunny-monitor\nspec:\nselector:\nmatchLabels:\napp: bunny-rest-proxy\nendpoints:\n- port: metrics\n</code></pre>"},{"location":"deployment/#logging","title":"Logging","text":"<p>By default, Bunny REST Proxy prints logs at <code>info</code> verbosity level in JSON format:</p> <pre><code>{\"level\":30,\"time\":1654594153537,\"pid\":1,\"hostname\":\"bunny-rest-proxy-bf9d996d6-z26hr\",\"reqId\":\"req-ikyv\",\"req\":{\"method\":\"GET\",\"url\":\"/consume/json-queue\",\"hostname\":\"bunny-service:3672\",\"remoteAddress\":\"10.244.0.37\",\"remotePort\":45112},\"msg\":\"incoming request\"}\n</code></pre> <p>Log level can be changed by specifying the <code>BRP_LOG_LEVEL</code> environment variable (possible values are: <code>fatal</code>, <code>error</code>, <code>warn</code>, <code>info</code>, <code>debug</code>, <code>trace</code> and <code>child</code>).</p>"},{"location":"deployment/#pretty-format","title":"Pretty format","text":"<p>Logger can be optionally configured to print logs in pretty format (provided by <code>pino-pretty</code>) by setting the <code>BRP_LOG_PRETTY</code> environment variable to <code>true</code>:</p> <pre><code>[06:53:57 UTC] INFO (1 on d9ee0a4a95b8): request completed\n    res: {\n      \"statusCode\": 205\n    }\n    responseTime: 0.6390420002862811\n    reqId: \"req-m\"\n</code></pre>"},{"location":"deployment/#metrics","title":"Metrics","text":"<p>Bunny REST Proxy provides a built-in Prometheus exporter which exposes metrics on port 9672 (<code>/metrics</code> endpoint).</p> <p>The following metrics are collected:</p> <ul> <li><code>publisher_latency</code> histogram - latency of HTTP POST publisher requests labeled with: <code>queue</code> - the name of a queue and <code>status</code> - response HTTP status code</li> <li><code>consumer_latency</code> histogram - latency of HTTP GET consumer requests labeled with: <code>queue</code> - the name of a queue and <code>status</code> - response HTTP status code</li> <li><code>subscriber_latency</code> histogram - latency of HTTP POST (PUSH) subscriber requests sent to the subscriber's target labeled wit: <code>queue</code> - the name of a queue, <code>target</code> - URL of the subscriber target and <code>status</code> - response HTTP status code</li> <li><code>subscriber_failed_messages</code> counter - number of messages that failed the initial delivery attempt (and might have been scheduled for retry depending on subscriber config) labeled with: <code>queue</code> - the name of a queue and <code>target</code> - URL of the subscriber target</li> <li><code>subscriber_dead_messages</code> counter - number of messages that exceeded the maximum number of delivery retries (and were dealt with according to the specified dead letter policy) labeled with: <code>queue</code> - the name of a queue and <code>target</code> - URL of the subscriber target</li> <li>a suite of standard Node.js metrics collected by the <code>prom-client</code> library</li> </ul>"},{"location":"deployment/#performance","title":"Performance","text":"<p>Bunny REST Proxy performance depends heavily on the performance offered by the underlying RabbitMQ queues. In some preliminary load tests conducted using gocannon, when running a single instance of Bunny REST Proxy against a RabbitMQ broker located on the same host, the following results were obtained on a Skylake-based machine with a relatively high CPU clock:</p> <ul> <li>Maximum publisher throughput of 14k HTTP POST req/s</li> <li>Maximum consumer throughput of 7k HTTP GET req/s</li> <li>Maximum subscriber throughput of 3.5k HTTP POST req/s sent its target</li> </ul> <p>While the figures listed above are sensitive to a wide variety of additional factors such as network latency, subscriber target endpoint latency or the performance of the underlying RabbitMQ broker, ratios close to 4:2:1 (publisher:consumer:subscriber throughput) were observed when repeating the tests on less performant hardware. It is worth noting that publishers, consumers and subscribers were tested in isolation and therefore lower performance metrics should be expected when running a mixed workload.</p>"},{"location":"deployment/#application-lifecycle","title":"Application lifecycle","text":""},{"location":"deployment/#graceful-shutdown","title":"Graceful shutdown","text":"<p>Upon receiving <code>SIGINT</code> or <code>SIGTERM</code> signal, Bunny REST Proxy instance performs a graceful shutdown procedure. When the app is in a graceful shutdown state, the following changes occur:</p> <ul> <li>AMQP consumers are stopped so as not to receive new messages.</li> <li>Pending publisher and consumer HTTP requests that were received prior to receiving the signal are processed without interruptions.</li> <li>New publisher and consumer HTTP requests (incoming after the app went into graceful shutdown mode) receive HTTP status code <code>503</code>.</li> <li>Subscriber messages that failed the first delivery attempt and were placed in the in-memory retry queue of a given instance are nacked (marked for re-delivery at the RabbitMQ level).</li> <li>Subscriber messages that have their corresponding HTTP POST (PUSH) requests in-flight are allowed to continue. Bunny REST Proxy will check for existence of in-flight messages every second up to 5 times before forcefully closing the process. </li> </ul> <p>When all of the AMQP consumers are closed, there are no in-flight subscriber message deliveries and all of the incoming HTTP requests are responded to, Bunny REST Proxy will close both of its AMQP channels (regular channel as well as channel with publisher confirms) and the AMQP connection. Following that, the process will exit.</p>"},{"location":"deployment/#error-shutdown","title":"Error shutdown","text":"<p>When either one of the application instance's AMQP channels or the AMQP connection is closed unexpectedly (which may happen as a result of an AMQP error), Bunny REST Proxy performs a simplified shutdown procedure, during which no communication is performed with the RabbitMQ cluster (AMQP consumers aren't stopped, messages placed in the in-memory retry queue aren't nacked and neither the channels nor the AMQP connection are closed).</p>"},{"location":"getting-started/","title":"Getting started","text":"<p>In this guide you will spin up a Bunny REST Proxy instance with one JSON publisher and one consumer working on a single RabbitMQ queue.</p>"},{"location":"getting-started/#step-1-create-a-configuration-file","title":"Step 1: Create a configuration file","text":"<p>Entire configuration of Bunny REST Proxy is declared in a single file named <code>config.yml</code>. Let's create one defining a publisher and a consumer:</p> <pre><code>cat &lt;&lt;EOT &gt;&gt; config.yml\n---\npublishers:\n  - queueName: json-queue\n    contentType: json\n\nconsumers:\n  - queueName: json-queue\nEOT\n</code></pre>"},{"location":"getting-started/#step-2-spin-up-docker-containers","title":"Step 2: Spin up Docker containers","text":"<p>Since we will have to spin up both Bunny REST Proxy and RabbitMQ, let's create a new Docker network for both containers to communicate in:</p> <pre><code>docker network create bunny\n</code></pre> <p>After that, let's run a new RabbitMQ container named <code>rabbitmq</code> connected to the <code>bunny</code> network:</p> <pre><code>docker run -d --hostname rabbit --net bunny --name rabbitmq rabbitmq:3-management\n</code></pre> <p>And finally, let's start a new Bunny REST Proxy container:</p> <pre><code>docker run -p 3672:3672 -v $(pwd)/config.yml:/app/config.yml --net bunny \\\n--env BRP_CONN_STR=\"amqp://guest:guest@rabbitmq:5672?heartbeat=30\" -d \\\nkffl/bunny-rest-proxy\n</code></pre> <p>As you can see, we are providing Bunny REST Proxy with a connection string to the RabbitMQ instance via <code>BRP_CONN_STR</code> environment variable, binding its port 3672 to the same port number on the host machine and mounting our local <code>config.yml</code> file as <code>/app/config.yml</code> inside the container.</p>"},{"location":"getting-started/#step-3-send-and-receive-some-messages","title":"Step 3: Send and receive some messages","text":"<p>Once we have both Bunny REST Proxy and RabbitMQ up and running, let's test it by publishing a single message via HTTP POST request:</p> <pre><code>curl --request POST \\\n--url http://localhost:3672/publish/json-queue \\\n--header 'Content-Type: application/json' \\\n--data '{\"hello\": \"bunny\"}'\n</code></pre> <p>You should obtain a result looking something like this:</p> <pre><code>{\"contentLengthBytes\":18, \"messageId\":\"ea34c68d-f6eb-2c44-aa4e-8d85ee46dd26\"}\n</code></pre> <p>Now, let's consume the previously published message using a GET request:</p> <pre><code>curl --request GET \\\n--url http://localhost:3672/consume/json-queue\n</code></pre> <p>And voila, you should have received your JSON message:</p> <pre><code>{\"hello\": \"bunny\"}\n</code></pre>"},{"location":"getting-started/#wrapping-up","title":"Wrapping up","text":"<p>While this guide was supposed to give you a basic understanding of what Bunny REST Proxy can be used for, we are barely scratching the surface in terms of the functionality it has to offer. We haven't even touched on subscribers, which allow for pushing messages from a queue to specified HTTP targets with retry backoff strategies and dead letter policies. Publishers also offer additional functionalities such as server-side JSON schema validation or ACL-based authorization.</p>"},{"location":"consumers/consumer-config/","title":"Consumer configuration","text":"<p>Consumer are used for pull-based retrieval of messages one-by-one from queues using HTTP GET requests. Unlike subscribers, which support reliable message delivery with retries and dead letter policy, consumers auto-acknowledge each retrieved message (via AMQP RPC-based GET operation) so that it won't be re-delivered. For that reason, getting messages from a queue via a consumer HTTP GET requests shall not be used when at-least-once delivery semantics are desired.</p> <p>Consumers are declared in the <code>consumers</code> block of the <code>config.yml</code> file:</p> <pre><code>consumers:\n- queueName: json-queue\n- queueName: binary-queue\nidentities:\n- Bob\n</code></pre> <p>The example YAML configuration provided above creates two consumers. The first one allows anyone to consume messages from <code>json-queue</code>, whereas the other consumer only allows identity named <code>Bob</code> to consume messages from <code>binary-queue</code>.</p>"},{"location":"consumers/consumer-config/#consumer-configuration-reference","title":"Consumer configuration reference","text":"<p>Warning</p> <p>When <code>identities</code> field is not provided or contains an empty array, the consumer endpoint authentication is bypassed.</p> <p>The following keys can be specified in the consumer configuration block:</p> <ul> <li><code>queueName</code> (required): the name of the queue, from which the consumer will be getting messages upon each HTTP GET request.</li> <li><code>identities</code>: a list of identity names permitted to consume messages via a given consumer.</li> </ul>"},{"location":"consumers/consuming-messages/","title":"Consuming messages","text":"<p>Consuming messages is done by sending a HTTP GET request to the following endpoint:</p> <p><code>http://bunny-rest-proxy.host:3672/consume/&lt;queueName&gt;</code></p>"},{"location":"consumers/consuming-messages/#http-request-headers","title":"HTTP Request Headers","text":"<ul> <li><code>X-Bunny-Identity</code>: optional identity name</li> <li><code>X-Bunny-Token</code>: optional identity token</li> </ul>"},{"location":"consumers/consuming-messages/#possible-response-codes","title":"Possible Response Codes","text":"<ul> <li><code>205</code>: Message retrieved successfully. Note that the <code>205</code>/Reset Content HTTP code indicates that consuming messages is a destructive operation, as they are auto-acknowledged upon retrieval.</li> <li><code>403</code>: Identity authorization failed or required credentials not provided request headers</li> <li><code>423</code>: Queue is empty.</li> <li><code>500</code>: Something unexpected and rather bad happened.</li> <li><code>502</code>: An AMQP error occurred when getting the message from the queue.</li> <li><code>503</code>: Bunny REST Proxy is during the graceful shutdown process.</li> </ul>"},{"location":"consumers/consuming-messages/#response-headers","title":"Response Headers","text":"<ul> <li><code>Content-Type</code>: content type of the message.</li> <li><code>X-Bunny-MessageID</code>: ID of the consumed message.</li> <li><code>X-Bunny-CorrelationID</code>: ID of the consumed message.</li> <li><code>X-Bunny-AppID</code>: app ID of the program that sent the message to the queue.</li> <li><code>X-Bunny-Message-Count</code>: number of messages that are remaining in the queue.</li> </ul>"},{"location":"consumers/consuming-messages/#response-body","title":"Response Body","text":"<p>In case of the message being retrieved successfully, the response body will contain the message content.</p>"},{"location":"identities/configuring-identities/","title":"Configuring Identities","text":"<p>Bunny REST Proxy supports ACL-style authorization via identities that are declared in the <code>identities</code> block of <code>config.yml</code>. Referencing a defined identity in publisher or consumer configuration will result in their corresponding HTTP endpoints requiring authorization via appropriate request headers containing identity name and token. Below is an example of <code>identities</code> block with two entries:</p> <pre><code>identities:\n- name: Bob\n- name: Alice\ntoken: SuperSecretToken123\n</code></pre> <p>Since unlike Alice's identity, Bob's doesn't supply a token, Bunny REST Proxy will attempt to read it from <code>BRP_TOKEN_Bob</code> environment variable at startup.</p>"},{"location":"identities/configuring-identities/#referencing-identities","title":"Referencing identities","text":"<p>Both publisher and consumer configuration blocks support <code>identities</code> key containing an array of authorized identity names. Below is an example of a single publisher granting access to its HTTP endpoint only to Alice:</p> <pre><code>  - queueName: json-with-auth\ncontentType: json\nidentities:\n- Alice\n</code></pre> <p>In order to publish messages to the <code>json-with-auth</code> queue via HTTP POST requests sent to <code>/publish/json-with-auth</code> endpoint, the following request headers will have to be supplied:</p> <ul> <li><code>X-Bunny-Identity: Alice</code></li> <li><code>X-Bunny-Token: SuperSecretToken123</code></li> </ul>"},{"location":"publishers/publisher-config/","title":"Publisher configuration","text":"<p>Publishers are used in order to send messages to RabbitMQ queues over HTTP. They are defined in the <code>publishers</code> block of the <code>config.yml</code> file. Below is an example of <code>publishers</code> block defining two publishers:</p> <pre><code>publishers:\n- queueName: binary-queue\ncontentType: binary\nconfirm: true\n- queueName: json-queue\ncontentType: json\nconfirm: false\nschema:\nproperties:\nid:\ntype: string\neventStatus:\nenum:\n- IN_PROGRESS\n- PENDING\n- PLANNED\noptionalProperties:\nnotes:\ntype: string\n</code></pre> <p>The first publisher in the example provided above will publish binary messages into <code>binary-queue</code> RabbitMQ queue. Messages will be published using a channel with publisher confirms so as to ensure that the message is persisted in the broker prior to sending the response back to the publisher's client. The other publisher will only accept JSON message payload adhering to a specified schema.</p>"},{"location":"publishers/publisher-config/#publisher-configuration-reference","title":"Publisher configuration reference","text":"<p>Warning</p> <p>When <code>identities</code> field is not provided or contains an empty array, the publisher endpoint authorization is bypassed.</p> <p>The following keys can be specified in the publisher configuration block:</p> <ul> <li><code>queueName</code> (required): the name of the queue, to which the messages will be published.</li> <li><code>contentType</code>: content type accepted by the publisher - either <code>binary</code> or <code>json</code>. Defaults to <code>binary</code>.</li> <li><code>confirm</code>: whether or not a channel with publisher confirms be used for sending messages to the queue. Defaults to <code>true</code>.</li> <li><code>schema</code>: schema to validate the message against before sending it to the queue. Supports both JSON Schema <code>draft-07</code> specification and JSON Type Definition.</li> <li><code>identities</code>: a list of identity names permitted to publish messages via a given publisher.</li> </ul>"},{"location":"publishers/publishing-messages/","title":"Publishing messages","text":"<p>Publishing messages is done by sending a HTTP POST request to the following endpoint:</p> <p><code>http://bunny-rest-proxy.host:3672/publish/&lt;queueName&gt;</code></p>"},{"location":"publishers/publishing-messages/#http-request-headers","title":"HTTP Request Headers","text":"<ul> <li><code>Content-Type</code> (required): either <code>application/octet-stream</code> for binary publishers or <code>application/json</code> for JSON publishers</li> <li><code>X-Bunny-Persistent</code>: mark the message as persistent (surviving broker restarts; defaults to <code>true</code>)</li> <li><code>X-Bunny-AppID</code>: optional ID of the program publishing the message</li> <li><code>X-Bunny-CorrelationID</code>: optional correlation ID to be attached to the published message</li> <li><code>X-Bunny-Identity</code>: optional sender identity name</li> <li><code>X-Bunny-Token</code>: optional sender identity token</li> </ul>"},{"location":"publishers/publishing-messages/#possible-response-codes","title":"Possible Response Codes","text":"<ul> <li><code>201</code>: Message sent successfully</li> <li><code>400</code>: Payload schema validation failed</li> <li><code>403</code>: Identity authorization failed or credentials not provided request headers</li> <li><code>415</code>: Unsupported content type</li> <li><code>500</code>: Something unexpected and rather bad happened.</li> <li><code>502</code>: An AMQP error occurred when sending the message to the queue.</li> <li><code>503</code>: Bunny REST Proxy is during the graceful shutdown process.</li> </ul>"},{"location":"publishers/publishing-messages/#response-body","title":"Response Body","text":"<p>In case of the message being sent successfully, JSON response containing the following keys is returned:</p> <ul> <li><code>contentLengthBytes</code>: number of bytes of the sent message body</li> <li><code>messageId</code>: UUID of the message generated by Bunny REST Proxy</li> </ul>"},{"location":"subscribers/dead-letter-policies/","title":"Dead letter policies","text":"<p>A dead letter policy specifies what happens to a particular message when it exceeds the maximum number of delivery retries.</p> <p>A total of three dead letter policies are supported:</p>"},{"location":"subscribers/dead-letter-policies/#nackrequeue-message-requeue","title":"Nack/requeue message (<code>requeue</code>)","text":"<p>When a message exceeds the maximum number of HTTP POST delivery attempts, it will be negatively acknowledged by the underlying AMQP consumer and consequently requeued by RabbitMQ so that it can be redelivered again.</p>"},{"location":"subscribers/dead-letter-policies/#ackdiscard-message-discard","title":"Ack/discard message (<code>discard</code>)","text":"<p>When a message exceeds the maximum number of HTTP POST delivery attempts, it will be acknowledged by the underlying AMQP consumer and thus discarded (no other consumer will be able to retrieve that message in the future).</p>"},{"location":"subscribers/dead-letter-policies/#send-a-message-to-dead-letter-queue-dlq","title":"Send a message to dead letter queue (<code>dlq</code>)","text":"<p>After exceeding the maximum number of delivery attempts, the message will be sent to a dead letter queue specified in the subscriber configuration (<code>deadLetterQueueName</code>). After having received publisher confirm indicating that the message was successfully sent to DLQ, Bunny REST Proxy will then acknowledge the message in the original queue.</p>"},{"location":"subscribers/message-format/","title":"Message PUSH format","text":"<p>This section describes the format of HTTP POST requests sent by Bunny REST Proxy to subscribers' targets.</p>"},{"location":"subscribers/message-format/#request-headers","title":"Request Headers","text":"<ul> <li><code>Content-Type</code>: content type of the incoming message.</li> <li><code>X-Bunny-MessageID</code>: ID of the incoming message.</li> <li><code>X-Bunny-CorrelationID</code>: correlation ID of the incoming message.</li> <li><code>X-Bunny-Redelivered</code>: whether or not the message was marked as redelivered by the broker (not BRP subscriber).</li> <li><code>X-Bunny-Message-Count</code>: Approximate number of messages left in the queue.</li> <li><code>X-Bunny-Message-AppID</code>: ID of the program that sent the original message to the queue.</li> <li><code>X-Bunny-Message-From-Queue</code>: the name of the queue from which the message was retrieved.</li> </ul>"},{"location":"subscribers/message-format/#request-body","title":"Request Body","text":"<p>The request body contains the content of the retrieved message.</p>"},{"location":"subscribers/retry-backoff-strategies/","title":"Backoff strategies","text":"<p>A subscriber backoff strategy specifies after what delay should a failed message delivery (one that ended with a result other than subscriber target responding with HTTP 2XX code) be retried. A total of 6 backoff strategies are supported.</p>"},{"location":"subscribers/retry-backoff-strategies/#constant-backoff-strategy-constant","title":"Constant backoff strategy (<code>constant</code>)","text":"<p>Delivery of each message will be retried after a constant timeout specified as <code>retryDelay</code>.</p>"},{"location":"subscribers/retry-backoff-strategies/#linear-backoff-strategy-linear","title":"Linear backoff strategy (<code>linear</code>)","text":"<p>The n-th message delivery attempt will be performed after n * retryDelay milliseconds.</p>"},{"location":"subscribers/retry-backoff-strategies/#exponential-backoff-strategy-exponential","title":"Exponential backoff strategy (<code>exponential</code>)","text":"<p>The n-th message delivery attempt will be performed after 2<sup>n-1</sup> * retryDelay milliseconds.</p>"},{"location":"subscribers/retry-backoff-strategies/#randomized-backoff-strategy-variants-random","title":"Randomized backoff strategy variants (<code>*-random</code>)","text":"<p>Backoff strategies, names of which are suffixed with <code>-random</code> will for each n-th retry draw a random delay value that is between the value of n-1 attempt of the underlying backoff strategy and n+1 attempt of the underlying backoff strategy.</p> <p>Note</p> <p>One exception to the rule described above is the <code>constant-random</code> backoff strategy, which upon each retry produces a random value between 50% and 150% of <code>retryDelay</code>.</p> <p>Example:</p> <p>A linear backoff strategy with a base delay of 1000ms will produce a delay of 3000ms before the 3rd delivery attempt, 4000ms before the 4th delivery attempt and 5000ms before the 5th delivery attempt. Consequently, a randomized linear backoff strategy will during the 4th delivery attempt produce a random value between that of the 3rd attempt and 5th attempt of the linear backoff strategy, that is between 3000ms and 5000ms. </p>"},{"location":"subscribers/subscriber-config/","title":"Subscriber configuration","text":"<p>Subscribers are are used in order to push messages from a given RabbitMQ queues over HTTP to a specified target URL in a webhook-like fashion. They are defined in the <code>subscribers</code> block of the <code>config.yml</code> file. Below is an example of <code>subscribers</code> block defining two subscribers:</p> <pre><code>subscribers:\n- queueName: demo-queue\ntarget: http://somewhere.tld/handle-demo\nprefetch: 3\nbackoffStrategy: linear\nretries: 4\nretryDelay: 1000\ndeadLetterPolicy: requeue\n- queueName: another-queue\ntarget: http://somewhere.tld/handle-another\nbackoffStrategy: exponential-random\nretries: 5\nretryDelay: 2000\ndeadLetterPolicy: dlq\ndeadLetterQueueName: another-queue-dlq\n</code></pre>"},{"location":"subscribers/subscriber-config/#subscriber-configuration-reference","title":"Subscriber configuration reference","text":"<p>The following keys can be specified in the publisher configuration block:</p> <ul> <li><code>queueName</code> (required): the name of the queue, from which the subscriber will be consuming messages.</li> <li><code>target</code> (required): HTTP target to which the messages will be pushed via HTTP POST requests.</li> <li><code>prefetch</code>: The maximum number of unacknowledged messages being processed by the subscriber. Defaults to 10.</li> <li><code>timeout</code>: HTTP POST (PUSH) request timeout in milliseconds. Defaults to 2000.</li> <li><code>backoffStrategy</code>: The name of the backoff strategy to be used when retrying a failed HTTP POST message delivery attempt. Possible values are: <code>constant</code>, <code>constant-random</code>, <code>linear</code>, <code>linear-random</code>, <code>exponential</code> and <code>exponential-random</code>. Defaults to <code>linear</code>.</li> <li><code>retries</code>: The maximum number of failed message delivery retry attempts. Defaults to 5.</li> <li><code>retryDelay</code>: Base retry timeout in milliseconds between delivery retry attempts. Its value is used to calculate actual delays before n-th delivery attempt depending on the specified backoff strategy. Defaults to 1000.</li> <li><code>deadLetterPolicy</code>: The name of dead letter policy to be applied when a given message exceeds the maximum number of failed message delivery retries. Possible values are <code>requeue</code>, <code>discard</code> and <code>dql</code>. Defaults to <code>requeue</code>.</li> <li><code>deadLetterQueueName</code>: The name of dead letter queue to which a message will be sent after exceeding the maximum number of failed message delivery retries provided that the <code>deadLetterPolicy</code> is set to <code>dlq</code>.</li> </ul>"}]}